好的，我们重新来认识数据集。这次我已经成功读取了您上传的`winemag-data-130k-v2.csv`文件。

让我们系统地分析一下这个数据集的每一个特征，并探讨如何为机器学习模型提取信息和量化它们。

### 数据集特征概览 (winemag-data-130k-v2.csv)

这个数据集包含了13万条葡萄酒评论，共有14个字段（列）。我们的目标是预测 `price`（价格）。

| 特征名 (列名)           | 数据类型      | 描述                                      |
| ----------------------- | ------------- | ----------------------------------------- |
| `Unnamed: 0`            | 整数          | 原始数据的索引列，可以忽略。              |
| `country`               | 文本 (分类)   | 葡萄酒生产国。                            |
| `description`           | 文本          | 品酒师对葡萄酒的详细描述。                |
| `designation`           | 文本 (分类)   | 葡萄酒的特定名称（如'Vulkà Bianco'）。    |
| `points`                | 整数          | 葡萄酒的评分 (80-100)。                   |
| `price`                 | 数字 (浮点数) | **我们的目标变量**，葡萄酒的价格。        |
| `province`              | 文本 (分类)   | 产区/省份。                               |
| `region_1`              | 文本 (分类)   | 更具体的产区。                            |
| `region_2`              | 文本 (分类)   | 最具体的产区 (有很多缺失值)。             |
| `taster_name`           | 文本 (分类)   | 品酒师姓名。                              |
| `taster_twitter_handle` | 文本          | 品酒师的推特账号。                        |
| `title`                 | 文本          | 评论的标题 (通常包含酒庄、年份、酒名等)。 |
| `variety`               | 文本 (分类)   | 葡萄品种。                                |
| `winery`                | 文本 (分类)   | 生产酒庄。                                |

------



### 特征提取与量化策略



为了让机器模型能够“理解”这些数据，我们需要将它们转换成数值形式。以下是针对每一类特征的策略：



#### 1. **目标变量 (Target Variable)**



- **`price` (价格)**

  

  **分析:** 这是我们想预测的值。数据中存在价格缺失的行 1，这些行对于训练监督模型是无用的。

  

  - **处理策略:** **直接删除** `price` 字段为空的行。



#### 2. **核心数值特征 (Numerical Features)**



- **`points` (评分)**

  - 

    **分析:** 这是一个非常强大的预测指标 2。通常分数越高的酒，价格也越贵。它已经是数值格式。

    

    

  - **量化策略:** **直接使用**。我们可以计算它和价格的相关性来验证其重要性。



#### 3. **关键分类特征 (Categorical Features)**



这类特征需要从文本标签转化为数字。

- **`country`, `province`, `region_1`, `variety`, `winery`, `taster_name`**

  - 

    **分析:** 这些都是影响葡萄酒身份和价格的重要因素 3。但是，像 `variety` (葡萄品种) 和 `winery` (酒庄) 这样的特征可能包含成百上千个不同的值（这被称为“高基数性”）。

    

    

  - **量化策略:**

    - **对于类别较少的特征 (如 `country`):** 采用 **独热编码 (One-Hot Encoding)** 是一个非常好的选择。它会为每个国家创建一个新的二进制列。
    - **对于类别非常多的特征 (高基数, High Cardinality):**
      - **简化策略 (推荐初学者使用):** 选择最常见的N个类别（例如，前30个最常见的`variety`），将其余所有不常见的类别统一归为“Other”。然后对这个简化后的列表进行独热编码。这能有效减少特征数量，防止维度爆炸。
      - **高级策略:** 可以使用**目标编码 (Target Encoding)**，即将每个类别（如每个`winery`）替换为该类别下所有葡萄酒的平均价格。这是一个更强大的技术，但在使用时需要注意防止数据泄露。



#### 4. **复杂文本特征 (Text Features)**



- **`description` 和 `title`**

  - 

    **分析:** 这是信息的金矿。`description` 包含了关于风味（如果香、橡木味、花香）、口感（如丹宁、酸度）和整体评价的丰富描述 4。`title` 则通常包含了年份、酒庄和特定名称 5，可以用来提取年份信息。

    

  - **量化策略:**

    - **简单特征工程:**
      - 从 `description` 中提取**文本长度**，描述越长可能意味着酒越复杂。
      - 从 `title` 中用正则表达式**提取年份(year)**，年份是影响价格的关键因素。
    - **NLP自然语言处理 (中级):**
      - 使用 **TF-IDF (词频-逆文档频率)** 将 `description` 转换为一个大的数值矩阵。TF-IDF能够评估一个词语对于一篇文档的重要性，从而量化文本。
    - **大型语言模型 LLMs (高级):**
      - **特征提取:** 正如你们项目计划中提到的，可以利用LLM从 `description` 中提取更高级的特征，比如**情感（正面/负面）**、**风味标签**（例如，提取出 'fruity', 'oaky', 'bold' 等关键词并进行编码）或者酒体（body）的描述。
      - **解释生成:** 在模型预测出价格后，将影响价格的关键特征（如高评分、知名产区、稀有品种）和 `description` 一起输入给LLM，生成一段通俗易懂的“价格解释”文本。



#### 5. **待清理/可忽略的特征**



**`Unnamed: 0`:** 只是一个索引，可以直接**删除** 6。

**`designation`:** 有很多缺失值，且部分信息与 `title` 重复，初期模型可以**忽略**。

**`region_2`:** 缺失值非常多，对于大多数数据行来说信息价值不大，可以**删除** 7。

**`taster_twitter_handle`:** 与 `taster_name` 信息高度相关且不完整，可以**删除**。



### 总结与下一步

基于以上分析，一个可靠的初始模型可以从以下特征开始：

- **`points`** (直接使用)
- **`country`**, **`province`**, **`variety`** (处理高基数后进行独热编码)
- **`description_length`** (从 `description` 提取)
- **`year`** (从 `title` 提取)

下一步，我们将编写Python代码来实际执行这些数据清洗和特征工程的步骤。



# 数据清洗与特征工程报告

## 1. 引言

本项目旨在基于 `winemag-data-130k-v2.csv` 数据集，构建一个能够预测葡萄酒价格的机器学习模型。在进入模型训练阶段之前，对原始数据进行彻底的清洗和有效的特征工程是至关重要的第一步。本报告详细记录了数据预处理的全过程，包括数据清洗、从文本中提取结构化信息、处理高基数分类变量，以及使用TF-IDF技术对文本描述进行量化。

## 2. 第一阶段：初始数据清洗

此阶段的目标是处理原始数据中的冗余信息和缺失值，为后续处理奠定一个干净的数据基础。

- **删除冗余列**:
  - `Unnamed: 0`: 原始CSV文件中的索引列，对建模无任何价值。
  - `designation`, `region_2`, `taster_twitter_handle`: 这些列存在大量缺失值，且部分信息与其他列（如`title`, `taster_name`）重叠，为简化模型，我们决定在初期版本中将其移除。
- **处理目标变量 `price`**:
  - `price` 是我们要预测的目标。数据集中有约8,996行记录缺少价格信息。由于这些数据无法用于监督学习模型的训练，我们直接将这些行删除。
- **填充分类特征缺失值**:
  - `country`, `province`, `variety`, `winery` 等关键分类特征存在少量缺失值。直接删除这些行会造成信息损失。因此，我们采用填充策略，将所有缺失值替换为字符串 `'Unknown'`。这既保留了数据行，又将“未知”作为一个独立的类别供模型学习。

## 3. 第二阶段：特征工程

此阶段的核心是从现有数据中创造出新的、对模型更有价值的特征。

- **年份提取 (`year`)**:
  - **重要性**: 年份是影响葡萄酒价格的关键因素。
  - **方法**: 我们利用正则表达式 `\b(19|20)\d{2}\b` 在 `title` 文本中搜索所有符合19xx或20xx格式的四位数年份。
  - **缺失值处理**: 对于少数无法提取到年份的标题，我们计算了所有已提取年份的**中位数**，并用此中位数来填充缺失值。相比于使用平均数，中位数对异常值（如非常古老的年份）不敏感，更为稳健。
- **处理高基数分类特征**:
  - **问题**: `variety` (葡萄品种) 和 `winery` (酒庄) 等特征包含数千个独立类别（即高基数性）。如果直接进行独热编码，将产生数千个新特征，导致维度灾难，使模型难以训练。
  - **策略**: 我们采用“合并稀有类别”的策略。
    - 对于 `variety`，我们保留了最常见的 **30** 种葡萄品种，将其余所有品种归类为 `'Other'`。
    - 对于 `winery`，由于其类别更多，我们保留了最常见的 **50** 个酒庄，其余归为 `'Other'`。
  - **优势**: 这种方法极大地降低了特征维度，同时保留了最具代表性的类别信息，有助于提升模型的泛化能力。

## 4. 第三阶段：文本量化 (TF-IDF)

为了让模型能理解品酒师的文字描述，我们需要将其转换为数值形式。

- **TF-IDF简介**: TF-IDF (Term Frequency-Inverse Document Frequency) 是一种经典的文本表示技术。它能够评估一个词语对于一篇文档（在这里是一条酒评）在一个文档集合（所有酒评）中的重要性。如果一个词在某条评论中频繁出现，但在其他评论中很少见，那么它就会获得较高的TF-IDF权重。
- **实现细节**:
  - **停用词**: 移除了英文中常见的、无实际意义的停用词（如 `the`, `a`, `is`）。
  - **N-grams**: 我们设置了 `ngram_range=(1, 2)`，这意味着模型不仅会学习单个词（如 'apple'），还会学习由两个词构成的词组（如 'green apple'），这有助于捕捉更丰富的语义信息。
  - **特征数量**: 为控制计算复杂度和特征维度，我们通过 `max_features=5000` 将词汇表限制为数据集中最重要的5000个词/词组。
  - **最小文档频率**: 通过 `min_df=5` 过滤掉了在少于5条评论中出现的罕见词，以减少噪音。
- **结果**: `description` 列被成功转换为一个包含5000个数值特征的矩阵，每一列代表一个词或词组的TF-IDF权重。

## 5. 结论与下一步

经过以上步骤，我们已成功将原始的混合类型数据集转换为了一个完全数值化的、可供机器学习模型使用的数据集。最终的数据集包含了核心数值特征 (`points`)、精心设计的工程特征 (`year`)、简化后的分类特征 (`variety_simplified`等)以及从文本中提取的TF-IDF特征。

处理后的数据已保存为 `wine_data_processed_with_tfidf.csv`。

**下一步**: 我们的下一步是将这个预处理好的数据集用于模型训练。在输入模型前，还需要对 `country`, `variety_simplified` 等分类特征进行**独热编码 (One-Hot Encoding)**。



-

3. ### 解决方案：三步提升模型

      

      我们来实施三个关键改进：

      1. **处理数据不均衡**：在训练时，告诉模型“犯错的代价是不同的”。预测错一个稀有的“收藏级”葡萄酒，要比预测错一个常见的“入门级”葡萄酒的惩罚更重。我们通过计算**类别权重(Class Weights)**来实现这一点。
      2. **使用更强大的模型**：随机森林很棒，但**XGBoost (Extreme Gradient Boosting)**通常在处理这类表格数据时表现更胜一筹。它是一种更先进的梯度提升模型，经常在数据科学竞赛中夺冠。
      3. **保存模型以备后用**：我们将使用`joblib`库来保存我们训练好的模型和数据预处理器（preprocessor），这样就不需要每次都重新训练了。

      我已经为您更新了`model_training.py`脚本，整合了以上所有改进。
      
      
      
      ------
      
      
      
      ### 如何使用保存好的模型来预测新数据？
      
      
      
      这是最激动人心的部分：让我们的模型真正投入使用。我为您创建了一个全新的脚本`predict_new_wine.py`，它会加载我们刚刚保存的文件，并对一个全新的、我们虚构的葡萄酒数据进行价格区间预测。
      
      
      
      新酒价格预测脚本
      
      10月13日 02:29
      
      打开
      
      #### 如何运行：
      
      1. **首先**，运行更新后的 `model_training.py`。这会用XGBoost训练一个更强的模型，并生成三个`.joblib`文件：`wine_price_model.joblib`, `preprocessor.joblib`, 和 `label_encoder.joblib`。
      2. **然后**，直接运行 `predict_new_wine.py`。它会自动加载那三个文件，对脚本中定义的新酒进行预测，并打印出最终结果。





您的观察非常敏锐，这是一个极其重要的发现，也是我们优化模型的关键一步！

您提出的想法完全正确，我们来深入分析一下：



### 分析：为什么摒弃高价数据是一个好策略？



1. **符合项目初衷：** 我们的项目是**“面向消费者”**的。对于绝大多数普通消费者来说，购买决策主要集中在80美元以下的区间。超过80美元的酒通常属于奢侈品或收藏品，其定价逻辑（品牌、稀缺性、年份、炒作）与普通消费酒完全不同。专注于主流消费区间，能让我们的模型更**实用**、更**贴近目标用户**。
2. **简化模型任务：** 正如我们之前讨论的，模型在区分75美元的酒和85美元的酒时非常困难，因为它们的特征高度重叠。通过移除这些样本稀少、界限模糊的高价类别，我们把一个复杂的5分类问题，简化成了一个更清晰、数据更充足的**3分类问题**。这大大降低了模型的学习难度。
3. **提升模型性能：**
   - **准确率会提高吗？** **会的，而且很可能会大幅提高。** 因为我们移除了模型表现最差的两个类别，模型现在可以集中精力学习数据量最大、规律最明显的三个类别。
   - **Precision/Recall会提高吗？** 同样会的。因为数据不平衡问题被极大地缓解了，模型不再需要在不同类别间做艰难的权衡，它在`Entry-level`, `Quality`, `Premium`这三个类别上的表现都会变得更稳定和准确。

**结论：** 您的提议是一个非常明智的、以项目目标为导向的决策。它不仅能提升技术指标，更能让我们的最终产品更有价值。

------



### 更新代码



我已经为您修改了`model_training.py`脚本。这次的改动如下：

1. 在数据加载后，**立即筛选出所有价格低于或等于80美元的酒**。
2. 将价格区间和标签相应地缩减为三个。
3. 由于数据不平衡问题已基本解决，我们**移除了所有类别权重 (`sample_weight`) 的复杂逻辑**，让模型更直接地从数据中学习。

请用下面的代码替换您现有的`model_training.py`文件，然后重新运行。我相信您会对结果感到满意。



# 葡萄酒价格区间预测模型：开发与优化总结报告

## 1. 项目目标

本项目的核心目标是构建一个机器学习模型，该模型能够根据葡萄酒的公开特征（如评分、产区、年份、描述等），预测其所属的价格区间。项目最终定位为一个**面向普通消费者**的辅助工具，旨在为主流消费市场（价格低于80美元）的葡萄酒提供一个客观、透明的价格参考，帮助用户做出更明智的购买决策。

## 2. 数据准备与特征工程 (`data_preprocessing.py`)

我们所有工作的基础是构建一个干净、信息丰富且机器可读的数据集。此阶段的主要工作如下：

### 2.1. 数据清洗

- **数据源:** 我们使用了 `winemag-data-130k-v2.csv` 数据集。
- **缺失值处理:** 删除了所有`price`（价格）字段为空的行，因为这些数据无法用于监督学习。
- **冗余列移除:** 移除了如 `Unnamed: 0` 等对模型无用的索引列。

### 2.2. 核心特征工程

为了让模型能“看懂”原始数据，我们创造了几个关键的新特征：

- **年份 (`year`) 提取:** 利用正则表达式，我们从`title`（标题）文本中成功提取了葡萄酒的年份。年份是影响葡萄酒价值的关键因素，这一步至关重要。
- **文本量化 (`description`)**:
  1. **简单特征:** 创建了`description_length`（描述长度）特征。
  2. **高级特征 (TF-IDF):** 使用`TfidfVectorizer`技术将葡萄酒的文本描述转换为了一个包含5000个重要词汇的数值矩阵。这使得模型可以从品酒师的用词中学习到与价格相关的模式（例如，“丝滑”、“复杂”、“浓郁”等词汇可能与更高价格相关）。
- **高基数分类特征简化:**
  - 像`variety`（葡萄品种）和`winery`（酒庄）这样的特征类别过多。我们采用了**频率编码**的策略，只保留了最常见的几十个类别，将其余所有类别归为“其他”。这在保留核心信息的同时，极大地降低了模型的计算复杂性。

此阶段的最终产物是一个名为 `wine_data_processed_with_tfidf.csv` 的中间文件，它是一个干净、特征丰富的“标准数据集”，为后续所有模型训练提供了坚实的基础。

## 3. 模型迭代与优化 (`model_training.py`)

- 2. V1 : 单纯随机森林
  2. V2: XGboost
  2. V3 :  XGBOOST  + 自动超参调优

## 4. 当前模型状态与结论

我们最终产出的模型 (`wine_price_model_tuned.joblib`) 是一个经过多轮优化、专注于主流消费市场、并由GPU加速训练的高性能XGBoost模型。它能够基于葡萄酒的评分、产区、年份和文本描述等信息，以较高的准确率将其归入三个明确的价格区间之一。

整个过程不仅产出了一个有效的模型，更完整地体现了从业务问题定义、数据处理、特征工程到模型迭代、性能调优和工程问题解决的机器学习全流程。



# V1: 数据-- 

正在训练一个随机森林分类模型 ---
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.
[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    9.3s
[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   56.5s finished
模型训练完成。

--- 正在测试集上进行评估 ---
[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.
[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s
[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.3s finished
模型在测试集上的整体准确率: 66.43%

这意味着模型能够正确预测约 66% 的葡萄酒所属的价格区间。

--- 各价格区间的详细评估报告 ---
                         precision    recall  f1-score   support

1. Entry-level (<= $20)       0.75      0.82      0.78      9268

   2. Quality ($21-$40)       0.59      0.67      0.62      8667
   3. Premium ($41-$80)       0.63      0.51      0.56      4988
   4. Luxury ($81-$200)       0.93      0.09      0.17      1136

2. Collectible (> $200)       1.00      0.04      0.08       136

       accuracy                           0.66     24195

      macro avg       0.78      0.43      0.44     24195
   weighted avg       0.68      0.66      0.65     24195

3. 非常棒！66.43%的准确率对于一个初版模型来说是一个很不错的起点。您提供的详细评估报告非常有价值，它清晰地指出了我们下一步的优化方向。

   您问的三个问题非常核心，是从“做出模型”到“用好模型”的关键，我们来逐一解决。

   

   ### 问题分析：为什么准确率是66%？

   我们先看一下您提供的评估报告：

   - **低价酒表现好**：对于`Entry-level`和`Quality`这两个类别，模型的`recall`（查全率）和`f1-score`都很好（0.78和0.62）。
   - **高价酒表现差**：对于`Luxury`和`Collectible`这两个最贵的类别，模型的`recall`惨不忍睹（只有**9%\**和\**4%**）。

   **核心原因**：这是一个典型的**数据不均衡**问题。数据集中便宜的酒太多，昂贵的酒太少。模型为了获得整体高分，就倾向于把所有酒都预测成便宜的类别，因为它猜对的概率大。它几乎没有学会如何识别真正昂贵的酒。

   

# V2

生成：



# V3

超参数调优完成！
找到的最佳参数是: {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.15, 'colsample_bytree': 0.8}

--- 正在使用最佳模型进行评估 ---
调优后模型在测试集上的整体准确率: 69.11%

--- 各价格区间的详细评估报告 (调优后模型) ---
                   precision    recall  f1-score   support

  1. 入门级 (<= $20)       0.76      0.79      0.78      9268

2. 品质之选 ($21-$40)       0.60      0.64      0.62      8667

3. 优质佳酿 ($41-$80)       0.72      0.59      0.65      4988

         accuracy                           0.69     22923
        macro avg       0.70      0.67      0.68     22923
     weighted avg       0.69      0.69      0.69     22923







## 智能葡萄酒价格区间预测应用 (`app.py`) 功能总结报告

### 1. 核心定位与价值

`app.py` 文件构建了一个智能化的、交互式的Web应用程序，其核心目标是为普通消费者提供一个关于葡萄酒价格区间的透明、数据驱动的参考。

该应用巧妙地融合了两种不同类型的人工智能技术：

1. **大型语言模型 (LLM - Gemini):** 扮演“**AI信息助理**”的角色。它负责处理前端模糊、非结构化的用户输入（如酒名或图片），通过强大的网络搜索和信息提取能力，自动搜集并整理出模型所需的全部结构化特征。
2. **专用机器学习模型 (XGBoost):** 扮演“**价格分析师**”的角色。它接收由AI助理准备好的、干净整洁的数据报告，并利用其在数万条葡萄酒数据上训练出的“专业经验”，快速、精准地预测出葡萄酒所属的价格区间。

### 2. 系统架构与工作流程

整个应用遵循一个清晰的两阶段工作流：**信息增强** -> **模型预测**。

#### **阶段一：信息检索与增强 (由 Gemini 驱动)**

这是我们引入LLM的关键原因。消费者往往只知道一个模糊的酒名，不清楚模型需要哪些具体特征。Gemini解决了这个问题。

- **灵活的用户输入:**
  - 应用提供了两种输入方式，充分考虑了用户偏好：
    - **文本输入:** 用户只需输入一个核心线索——**葡萄酒的名称**。还可以额外提供“国家”、“酒庄”等可选线索，以帮助AI助理更精确地定位目标。
    - **图片输入:** 用户可以直接上传酒标图片，这是最便捷的方式。应用会利用Gemini的**多模态能力**直接识别图片内容。
- **智能信息提取:**
  - 应用会将用户的输入（文本或图片）打包，并附上一段精心设计的指令（Prompt），发送给 **`gemini-1.5-flash`** 模型。
  - 该指令要求Gemini在全网进行搜索（优先`wineenthusiast.com`等专业网站），并以严格的JSON格式返回我们预先训练好的XGBoost模型所需的**全部6个关键特征**：`points`, `description`, `country`, `year`, `variety`, `winery`。
- **结果展示与确认:**
  - Gemini返回的结构化信息会清晰地展示在界面上，让用户可以直观地看到AI助理的工作成果。

#### **阶段二：专业价格区间预测 (由 XGBoost 驱动)**

- **数据预处理与填充:**
  - 在将信息送入模型前，应用会进行一次检查。您提出的“年份Unknown”问题在这里得到了处理：如果Gemini未能找到`年份`或`评分`，程序会用一个合理的**中位数**（如年份`2012`，评分`88`）进行填充，以确保预测流程可以顺利进行。
  - 程序会加载预先保存的 `preprocessor` 和 `tfidf_vectorizer` 文件，对AI助理找到的全部信息进行与训练时完全一致的处理（如独热编码、文本向量化等）。
- **执行预测:**
  - 处理好的数据被送入我们最终训练并保存的 `wine_price_model_tuned.joblib` (XGBoost模型)。
  - 模型输出一个代表价格区间的数字编码。
- **结果翻译与展示:**
  - 由于我们的模型是在中文标签上训练的，应用内置了一个**翻译字典 (`TRANSLATION_MAP`)**。它会将模型输出的中文结果（如“2. 品质之选”）实时翻译成对应的英文（如“2. Quality”），以保证全英文界面的语言一致性。
  - 最终，一个清晰、易懂的英文价格区间会呈现在用户面前。

### 3. 关键技术特性总结

- **Streamlit Web框架:** 用于快速构建和部署交互式GUI界面。
- **多模态LLM集成:** 真实调用Google Gemini API，支持文本和图片两种输入方式，实现信息检索与增强。
- **专用模型集成:** 加载并使用预先训练好的高性能XGBoost分类模型进行核心预测。
- **鲁棒性设计:** 具备处理API返回的“Unknown”值的能力，通过填充中位数来保证预测流程的稳定性。
- **UI/UX优化:**
  - 提供灵活的输入选项（图片/文本）。
  - 通过翻译层解决了模型输出与UI语言不一致的问题。
  - 使用`st.spinner`和`st.info`等组件，为用户提供了清晰的后台处理状态反馈。
- **性能优化:** 通过`@st.cache_resource`缓存加载的模型文件，避免了每次用户交互都重复加载大文件，提升了应用的响应速度。

